{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHY408 Final Report\n",
    "Ben Pennell\n",
    "\n",
    "April 26th, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "from astropy.visualization import ImageNormalize, AsinhStretch\n",
    "from astropy.convolution import convolve, Gaussian2DKernel\n",
    "from photutils import detect_sources\n",
    "from astropy.stats import SigmaClip\n",
    "from photutils.background import Background2D, SExtractorBackground\n",
    "from scipy import stats as st\n",
    "from photutils.segmentation import SourceCatalog\n",
    "\n",
    "FITS_PATH = \"./A2390C.fits\"\n",
    "hdul = fits.open(FITS_PATH, memmap=False)\n",
    "data = hdul[0].data\n",
    "header = hdul[0].header\n",
    "hdul.close()\n",
    "\n",
    "SUBTRACTED_PATH = \"./cube_subtracted.fits\"\n",
    "SEGM_PATH = \"./segmentation_map.fits\"\n",
    "CUBE_LPF_PATH = \"./cube_lpf.fits\"\n",
    "DEEP_FRAME_PATH = \"./cube_deep_frame.fits\"\n",
    "START_INDEX = 42\n",
    "END_INDEX = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(image, size=7):\n",
    "    plt.rcParams[\"figure.figsize\"] = [size, size]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    \n",
    "    norm = ImageNormalize(vmin=np.median(image), vmax=np.median(image) + 3*np.std(image), stretch=AsinhStretch(a=0.1))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.imshow(image, origin=\"lower\", norm=norm)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wavenumber array\n",
    "min_wavenumber = header['CRVAL3']\n",
    "wavenumber_step = header['CDELT3']\n",
    "step_count = header['NAXIS3']\n",
    "max_wavenumber = min_wavenumber+(step_count-1)*wavenumber_step\n",
    "wavn_array = np.arange(min_wavenumber, max_wavenumber, wavenumber_step)\n",
    "wavn_array = wavn_array[START_INDEX:END_INDEX]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Fringes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segm_map(image, SN=5, npixels=5, sigma=3, size=128, return_all=False):\n",
    "    sigma_clip = SigmaClip(sigma=sigma)\n",
    "    bkg = Background2D(np.nan_to_num(image), (size, size), filter_size=(3, 3),\n",
    "                sigma_clip=sigma_clip, bkg_estimator=SExtractorBackground())\n",
    "    \n",
    "    threshold = bkg.background + (SN * bkg.background_rms)\n",
    "\n",
    "    sources = detect_sources(image, threshold, npixels=npixels)\n",
    "    \n",
    "    if return_all:\n",
    "        return sources\n",
    "    else:\n",
    "        return sources.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_background(image, sigma=3, size=128, SN=5, mask=None, iterations=1):\n",
    "    temp_image = image\n",
    "    for _ in range(iterations):\n",
    "        sigma_clip = SigmaClip(sigma=sigma)\n",
    "        mask = (segm_map(image, SN=SN) != 0)\n",
    "        bkg = Background2D(np.nan_to_num(image), (size, size), filter_size=(3, 3),\n",
    "                    sigma_clip=sigma_clip, bkg_estimator=SExtractorBackground(), coverage_mask=mask)\n",
    "        temp_image = temp_image - bkg.background\n",
    "    return temp_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data and create deep frame, segmentation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract backgrounds\n",
    "fixed_data = []\n",
    "for image in data:\n",
    "    image = image[50:-50,50:-50]\n",
    "    fixed_data.append(subtract_background(image))\n",
    "fixed_data = np.array(fixed_data)\n",
    "\n",
    "# collapse all images into one image by taking the max at each pixel\n",
    "deep_frame_initial = np.max(data[START_INDEX:END_INDEX,50:-50,50:-50], axis=0)\n",
    "\n",
    "# create the initial segmentation map - map of all detections\n",
    "segmentation_map_initial = segm_map(deep_frame_initial)\n",
    "\n",
    "# save background subtracted cube\n",
    "hdu = fits.PrimaryHDU(fixed_data)\n",
    "hdulist = fits.HDUList([hdu])\n",
    "hdulist.writeto(SUBTRACTED_PATH, overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_lpf = []\n",
    "for image in fixed_data[START_INDEX:END_INDEX]:\n",
    "    # set all values containing detected ELGs to 0\n",
    "    masked_image = np.where(segmentation_map_initial != 0, 0, image)\n",
    "\n",
    "    working_image = masked_image\n",
    "\n",
    "    # Gaussian kernel elongated in x direction\n",
    "    gaussian = Gaussian2DKernel(12, 3)\n",
    "\n",
    "    # Convolve with masked image\n",
    "    convolved_image = convolve(working_image, gaussian, \n",
    "                            mask=None, nan_treatment=\"fill\", normalize_kernel=True)\n",
    "\n",
    "    # subtract this high frequency image to only allow low frequencies\n",
    "    final_image = image - convolved_image\n",
    "    cube_lpf.append(final_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lpf\n",
    "hdu = fits.PrimaryHDU(cube_lpf)\n",
    "hdulist = fits.HDUList([hdu])\n",
    "hdulist.writeto(CUBE_LPF_PATH, overwrite=True)\n",
    "\n",
    "# save deep frame\n",
    "deep_frame_final = np.max(cube_lpf, axis=0)\n",
    "hdu = fits.PrimaryHDU(deep_frame_final)\n",
    "hdulist = fits.HDUList([hdu])\n",
    "hdulist.writeto(DEEP_FRAME_PATH, overwrite=True)\n",
    "\n",
    "# save segmentation map\n",
    "segm_map_final = segm_map(deep_frame_final)\n",
    "\n",
    "hdu = fits.PrimaryHDU(segm_map_final)\n",
    "hdulist = fits.HDUList([hdu])\n",
    "hdulist.writeto(SEGM_PATH, overwrite=True)\n",
    "\n",
    "segmentation_map_initial = segm_map(deep_frame_initial)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ha_line = 6562.819\n",
    "NII_u = 6583.460\n",
    "NII_l = 6548.050\n",
    "\n",
    "Ha_lower_ratio = 4\n",
    "Ha_upper_ratio = 12\n",
    "Ha_size = 1\n",
    "\n",
    "field_z = 0.228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(t, t_h):\n",
    "    amp = 1 / (np.sqrt(np.pi) * t_h)\n",
    "    exponent = - (t / t_h)**2\n",
    "    return amp * np.exp(exponent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ((1e8)/wavn_array[0] - (1e8)/wavn_array[len(wavn_array) - 1])/2\n",
    "wavl_gauss = np.arange(Ha_line - size, Ha_line + size, 1)\n",
    "\n",
    "index_NIIu = np.argmin(np.abs(NII_u - wavl_gauss))\n",
    "index_NIIl = np.argmin(np.abs(NII_l - wavl_gauss))\n",
    "index_ha = np.argmin(np.abs(Ha_line - wavl_gauss))\n",
    "\n",
    "template = np.zeros(len(wavl_gauss))\n",
    "template[index_ha] = Ha_size\n",
    "template[index_NIIu] = Ha_size / Ha_upper_ratio\n",
    "template[index_NIIl] = Ha_size / Ha_lower_ratio\n",
    "\n",
    "convolution_gaussian = []\n",
    "t_h = 3\n",
    "for t in np.arange(0, len(template), 1) - (0.5 * len(template)):\n",
    "    convolution_gaussian.append(gaussian(t, t_h))\n",
    "\n",
    "convolved_template = np.convolve(template, convolution_gaussian, mode=\"same\")\n",
    "wavl_gauss_shifted = wavl_gauss * (1 + field_z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_zeroes(series, number=None, both=False):\n",
    "    count = 0\n",
    "    if number is None:\n",
    "        power = np.ceil(np.log2(len(series)))\n",
    "        count = 2**power - len(series)\n",
    "    else:\n",
    "        count = number\n",
    "\n",
    "    if not both:\n",
    "        padded_series = np.concatenate((series, np.zeros(int(count))))\n",
    "        return padded_series\n",
    "    else:\n",
    "        padded_series = np.concatenate((np.zeros(int(count / 2)), series))\n",
    "        padded_series = np.concatenate((padded_series, np.zeros(int(count / 2))))\n",
    "        return padded_series\n",
    "    \n",
    "def normalize(x):\n",
    "    return (x-np.min(x))/(np.max(x)-np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_quality(cc):\n",
    "    return np.max(cc) / np.mean(abs(cc))\n",
    "\n",
    "def cross_correlate(x_centroid, y_centroid):\n",
    "    spectrum = fixed_data[:, int(y_centroid), int(x_centroid)]\n",
    "    spectrum = np.flip(spectrum[START_INDEX:END_INDEX])\n",
    "    wavelengths = np.linspace((1e8)/wavn_array[len(wavn_array) - 1], (1e8)/wavn_array[0], len(spectrum))\n",
    "\n",
    "    new_spectrum = np.interp(wavl_gauss_shifted, wavelengths, spectrum)\n",
    "\n",
    "    c_template = pad_zeroes(convolved_template)\n",
    "    c_spectrum = pad_zeroes(np.nan_to_num(new_spectrum))\n",
    "\n",
    "    cross_correlation = np.correlate(c_spectrum, c_template, mode=\"same\")\n",
    "\n",
    "    frequencies = np.fft.fftfreq(len(c_spectrum), 1) * len(c_spectrum)\n",
    "    lag_times = np.fft.fftshift(frequencies)\n",
    "\n",
    "    offset = np.argmax(cross_correlation)\n",
    "    offset = lag_times[offset]\n",
    "\n",
    "    observed = wavl_gauss_shifted[np.argmax(convolved_template)] + offset\n",
    "    redshift = (observed)/(Ha_line) - 1\n",
    "\n",
    "    sn = determine_quality(cross_correlation)\n",
    "\n",
    "    return (wavelengths, spectrum), offset, redshift, sn\n",
    "\n",
    "def create_catalogue(sources):\n",
    "    outdata = \"NAME X Y KRON_FLUX REDSHIFT QUALITY\"\n",
    "    gooddata = \"NAME X Y KRON_FLUX REDSHIFT QUALITY\"\n",
    "\n",
    "    for i, source in enumerate(sources):\n",
    "        x_centroid = source.centroid[0]\n",
    "        y_centroid = source.centroid[1]\n",
    "        kron_flux = source.kron_flux\n",
    "\n",
    "        spectra, offset, redshift, sn = cross_correlate(x_centroid, y_centroid)\n",
    "\n",
    "        line = \"\\n\" + str(i) + \" \" + str(round(x_centroid, 2)) + \" \" + str(round(y_centroid, 2)) + \" \" + str(round(kron_flux, 2)) + \" \" + str(round(redshift, 4)) + \" \" + str(round(sn, 2))\n",
    "        outdata += line\n",
    "        if sn > 4:\n",
    "            gooddata += line\n",
    "\n",
    "    outfile = open(\"all_objects.txt\", \"w\")\n",
    "    outfile.write(outdata)\n",
    "\n",
    "    goodfile = open(\"catalogue.txt\", \"w\")\n",
    "    goodfile.write(gooddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = segm_map(deep_frame_final, SN=5, return_all=True)\n",
    "\n",
    "cat = SourceCatalog(deep_frame_final, detections)\n",
    "\n",
    "create_catalogue(cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
